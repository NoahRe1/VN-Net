base_dir: data/model
log_level: INFO


data:
  region: 'd96' # d60 NE / d96 SW / d139 SE
  station_path: 'data/small_weather2K_split96.npy'
  station_mean_std_path: 'data_process/mean_std_d96.npy'

  image_path : 'data/H8_SW_160x160_96.npy'
  image_max_min_path : 'data_process/max_min_d96.npy'

  is_random: False  # whether to use random data as satellite images

  test_batch_size: 128
  batch_size: 16
  label_id: 8   # 4 temp / 8 hum / 16 ws / 21 vis10
  n_his: 12
  n_pred: 12
  use_single: false
  use_time_emb: true


model:
  model_name: VNNET

  image_encoder:
    type: MLVFEM

  graph_encoder:
    type: DEGCN
  
  fusion_method:
    type: LGVNFM
  
  graph_decoder:
    type: AGCRN

  node_num: 96
  input_dim: 23
  output_dim: 1
  seq_len: 12
  horizon: 12
  use_curriculum_learning: true
  cl_decay_steps: 2000
  l1_decay: 0
  max_view: 6
  layer_num: 2 
  rnn_units: 32
  embed_dim: 8
  location_dim: 2
  hidden_units: 256

  dgnn:
    #ODE
    time: 1
    method: 'euler'  

    augment: False
    adjoint: False
    tol_scale: 1.0
    tol_scale_adjoint: 1.0
    step_size: 0.25
    max_iters: 100
    adjoint_method: 'adaptive_heun'
    adjoint_step_size: 1
    max_nfe: 1000
    
    #GNN
    hidden_dim: 64
    embed_dim: 8
    block: 'constant'
    function: 'gread'
    dropout: 0.3
    batch_norm: True
    use_mlp: False
    fc_out: False
    m2_mlp: False
    input_dropout: 0.5
    XN_activation: False
    alpha_dim: 'sc'
    source_dim: 'sc'
    beta_dim: 'vc'
    no_alpha_sigmoid: True
    dyG: True
    Temb: True

    #regularisation args
    jacobian_norm2: 
    total_deriv: 
    kinetic_energy: 
    directional_penalty: 
    beltrami: False
    reaction_term: 'diffusion'
    beta_diag: True
    nox0: False
    add_source: False

train:
  log_dir: 'experiments/mlvfem_degcn_lgvnfm'
  experiment_name: 'd96_hum'
  epoch: 0
  epochs: 100
  base_lr: 0.005
  epsilon: 0.001
  steps:
  - 10
  - 20
  - 30
  - 40
  - 50
  patience: 15
  lr_decay_ratio: 0.5
  test_every_n_epochs: 10
  dropout: 0
  min_learning_rate: 1.0e-08
  optimizer: adam
  weight_decay: 0.0001
  M: 24
  d: 6
  bn_decay: 0.1

  
gpu: 0